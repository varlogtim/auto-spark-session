{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import auto_spark_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "storage_accounts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_account_names = [sa['storage_account_name'] for sa in storage_accounts]\n",
    "storage_paths = [\n",
    "    auto_spark_session.build_storage_path(sa['storage_account_name'], sa['container_name'], sa['uri'].lstrip(\"/\"))\n",
    "    for sa in storage_accounts\n",
    "]\n",
    "spark_session = auto_spark_session.get_session(storage_account_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark_readers = [spark_session.read.parquet(sp) for sp in storage_paths]\n",
    "\n",
    "left_rows = spark_readers[0].toLocalIterator()\n",
    "right_rows = spark_readers[1].toLocalIterator()\n",
    "\n",
    "for ii in range(min([sr.count() for sr in spark_readers])):\n",
    "    row_left = next(left_rows)\n",
    "    row_right = next(right_rows)\n",
    "\n",
    "    if not ii % 1000:\n",
    "        print(f\"total rows processed ({ii}), \"\n",
    "            f\"row_left: id: {row_left['id']}, squared: {row_left['squared_value']}, \"\n",
    "            f\"row_right: id: {row_right['id']}, squared: {row_right['squared_value']}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
